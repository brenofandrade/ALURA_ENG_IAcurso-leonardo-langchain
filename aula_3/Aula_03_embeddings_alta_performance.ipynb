{"cells":[{"cell_type":"markdown","id":"f92481e6","metadata":{"id":"f92481e6"},"source":["# Aula 3: Embeddings de Alta Performance\n","\n","## O que vamos aprender:\n","- Comparar modelos de API (Gemini) vs. modelos locais (Hugging Face) em custo, velocidade e qualidade.\n","- Aumentar a eficiência do processamento em 10x com **Batch Processing**.\n","- Economizar custos e reduzir a latência com **Cache de Embeddings**.\n","\n","### Por que a performance dos embeddings é crucial?\n","- **Qualidade da Busca**: A precisão do seu RAG depende diretamente da qualidade dos embeddings.\n","- **Custo Operacional**: Modelos locais podem reduzir drasticamente os custos de API em larga escala.\n","- **Velocidade (Latência)**: O tempo para gerar embeddings impacta a velocidade de indexação e a resposta ao usuário.\n","- **Privacidade**: Modelos locais garantem que dados sensíveis permaneçam na sua infraestrutura."]},{"cell_type":"markdown","id":"2c67a2c5","metadata":{"id":"2c67a2c5"},"source":["## 0. Configuração\n","\n","Instalamos as bibliotecas e configuramos a chave de API do Google."]},{"cell_type":"code","execution_count":1,"id":"3379606e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20519,"status":"ok","timestamp":1753475294688,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"3379606e","outputId":"f6abf211-b532-4265-81a1-9450df245620"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n","Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.8)\n","Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n","Requirement already satisfied: langchain-core\u003c1.0.0,\u003e=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.71)\n","Requirement already satisfied: langchain-text-splitters\u003c1.0.0,\u003e=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n","Requirement already satisfied: langsmith\u003e=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.8)\n","Requirement already satisfied: pydantic\u003c3.0.0,\u003e=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n","Requirement already satisfied: SQLAlchemy\u003c3,\u003e=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n","Requirement already satisfied: requests\u003c3,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n","Requirement already satisfied: PyYAML\u003e=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n","Requirement already satisfied: filetype\u003c2.0.0,\u003e=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n","Requirement already satisfied: google-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n","Requirement already satisfied: transformers\u003c5.0.0,\u003e=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n","Requirement already satisfied: torch\u003e=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.0)\n","Requirement already satisfied: huggingface-hub\u003e=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.4)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n","Requirement already satisfied: typing_extensions\u003e=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n","Requirement already satisfied: numpy\u003e=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n","Requirement already satisfied: aiohttp\u003c4.0.0,\u003e=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.14)\n","Requirement already satisfied: tenacity!=8.4.0,\u003c10,\u003e=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n","Requirement already satisfied: dataclasses-json\u003c0.7,\u003e=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n","Requirement already satisfied: pydantic-settings\u003c3.0.0,\u003e=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n","Requirement already satisfied: httpx-sse\u003c1.0.0,\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain-community) (2.6.1)\n","Requirement already satisfied: aiosignal\u003e=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain-community) (1.4.0)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain-community) (25.3.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain-community) (1.7.0)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain-community) (6.6.3)\n","Requirement already satisfied: propcache\u003e=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain-community) (0.3.2)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain-community) (1.20.1)\n","Requirement already satisfied: marshmallow\u003c4.0.0,\u003e=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json\u003c0.7,\u003e=0.5.7-\u003elangchain-community) (3.26.1)\n","Requirement already satisfied: typing-inspect\u003c1,\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json\u003c0.7,\u003e=0.5.7-\u003elangchain-community) (0.9.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (2.25.1)\n","Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (2.38.0)\n","Requirement already satisfied: proto-plus\u003c2.0.0,\u003e=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (1.26.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,\u003c7.0.0,\u003e=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (5.29.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.20.0-\u003esentence-transformers) (3.18.0)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.20.0-\u003esentence-transformers) (2025.3.0)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.20.0-\u003esentence-transformers) (25.0)\n","Requirement already satisfied: hf-xet\u003c2.0.0,\u003e=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub\u003e=0.20.0-\u003esentence-transformers) (1.1.5)\n","Requirement already satisfied: jsonpatch\u003c2.0,\u003e=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core\u003c1.0.0,\u003e=0.3.66-\u003elangchain) (1.33)\n","Requirement already satisfied: httpx\u003c1,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith\u003e=0.1.17-\u003elangchain) (0.28.1)\n","Requirement already satisfied: orjson\u003c4.0.0,\u003e=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith\u003e=0.1.17-\u003elangchain) (3.11.0)\n","Requirement already satisfied: requests-toolbelt\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith\u003e=0.1.17-\u003elangchain) (1.0.0)\n","Requirement already satisfied: zstandard\u003c0.24.0,\u003e=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith\u003e=0.1.17-\u003elangchain) (0.23.0)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c3.0.0,\u003e=2.7.4-\u003elangchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c3.0.0,\u003e=2.7.4-\u003elangchain) (2.33.2)\n","Requirement already satisfied: typing-inspection\u003e=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic\u003c3.0.0,\u003e=2.7.4-\u003elangchain) (0.4.1)\n","Requirement already satisfied: python-dotenv\u003e=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings\u003c3.0.0,\u003e=2.4.0-\u003elangchain-community) (1.1.1)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2-\u003elangchain) (3.4.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2-\u003elangchain) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2-\u003elangchain) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests\u003c3,\u003e=2-\u003elangchain) (2025.7.14)\n","Requirement already satisfied: greenlet\u003e=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy\u003c3,\u003e=1.4-\u003elangchain) (3.2.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers) (1.13.1)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1-\u003etorch\u003e=1.11.0-\u003esentence-transformers) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers\u003c5.0.0,\u003e=4.41.0-\u003esentence-transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers\u003c0.22,\u003e=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers\u003c5.0.0,\u003e=4.41.0-\u003esentence-transformers) (0.21.2)\n","Requirement already satisfied: safetensors\u003e=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers\u003c5.0.0,\u003e=4.41.0-\u003esentence-transformers) (0.5.3)\n","Requirement already satisfied: googleapis-common-protos\u003c2.0.0,\u003e=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (1.70.0)\n","Requirement already satisfied: grpcio\u003c2.0.0,\u003e=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (1.73.1)\n","Requirement already satisfied: grpcio-status\u003c2.0.0,\u003e=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,\u003c3.0.0,\u003e=1.34.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (1.71.2)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (5.5.2)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (0.4.2)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (4.9.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003e=0.1.17-\u003elangchain) (4.9.0)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003e=0.1.17-\u003elangchain) (1.0.9)\n","Requirement already satisfied: h11\u003e=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*-\u003ehttpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003e=0.1.17-\u003elangchain) (0.16.0)\n","Requirement already satisfied: jsonpointer\u003e=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch\u003c2.0,\u003e=1.33-\u003elangchain-core\u003c1.0.0,\u003e=0.3.66-\u003elangchain) (3.0.0)\n","Requirement already satisfied: mypy-extensions\u003e=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect\u003c1,\u003e=0.4.0-\u003edataclasses-json\u003c0.7,\u003e=0.5.7-\u003elangchain-community) (1.1.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2-\u003etorch\u003e=1.11.0-\u003esentence-transformers) (3.0.2)\n","Requirement already satisfied: pyasn1\u003c0.7.0,\u003e=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth!=2.24.0,!=2.25.0,\u003c3.0.0,\u003e=2.14.1-\u003egoogle-ai-generativelanguage\u003c0.7.0,\u003e=0.6.18-\u003elangchain-google-genai) (0.6.1)\n","Requirement already satisfied: sniffio\u003e=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio-\u003ehttpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003e=0.1.17-\u003elangchain) (1.3.1)\n"]}],"source":["!pip install langchain langchain-google-genai sentence-transformers scikit-learn langchain-community"]},{"cell_type":"code","execution_count":2,"id":"ce77aba1","metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1753475294717,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"ce77aba1"},"outputs":[],"source":["import os\n","import time\n","import numpy as np\n","\n","os.environ['GOOGLE_API_KEY'] = 'AIzaSyBDc4dXCuYxVb9bXWERnXNX95qmHtXaVxg'"]},{"cell_type":"markdown","id":"3fc9ab28","metadata":{"id":"3fc9ab28"},"source":["## 1. Comparativo de Modelos: Gemini (API) vs. Hugging Face (Local)\n","\n","Vamos comparar um modelo de ponta via API (Google Gemini) com modelos open-source populares que rodam localmente.\n","\n","- **Google Gemini (`embedding-001`)**: Modelo de alta qualidade, acessado via API.\n","- **`all-MiniLM-L6-v2`**: Um modelo local muito popular, leve e rápido. Ótimo para tarefas gerais onde a velocidade é importante.\n","- **`BAAI/bge-large-en-v1.5`**: Um dos melhores modelos open-source no MTEB Leaderboard. Mais pesado, mas com qualidade semântica superior."]},{"cell_type":"code","execution_count":3,"id":"8PFCcCvYfZzn","metadata":{"executionInfo":{"elapsed":8500,"status":"ok","timestamp":1753475303221,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"8PFCcCvYfZzn"},"outputs":[],"source":["from langchain_google_genai import GoogleGenerativeAIEmbeddings\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from sklearn.metrics.pairwise import cosine_similarity\n","import time"]},{"cell_type":"code","execution_count":4,"id":"vrwFRSvKR7zx","metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1753475303239,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"vrwFRSvKR7zx"},"outputs":[],"source":["# Textos de exemplo para nosso teste\n","textos_teste = [\n","    \"Qual é a política de férias da nossa empresa?\",\n","    \"Preciso de um relatório de despesas de viagem.\",\n","    \"Como configuro o acesso à rede privada virtual (VPN)?\",\n","    \"Onde encontro o código de conduta da organização?\",\n","    \"Quero entender o processo de avaliação de performance.\"\n","]"]},{"cell_type":"code","execution_count":5,"id":"8MVZAZTUR9SZ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1753475303565,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"8MVZAZTUR9SZ","outputId":"6a49ca8a-a7bd-4a24-b320-2013a8a1dcf8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tempo de processamento: 0.2647538185119629 segundos\n","  - Dimensões do vetor: 768\n"]}],"source":["## Google Gemnin Embeddings\n","\n","gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","\n","start_time = time.time()\n","embeddings_gemini = gemini_embeddings.embed_documents(textos_teste)\n","end_time = time.time()\n","\n","print(f\"Tempo de processamento: {end_time - start_time} segundos\")\n","print(f\"  - Dimensões do vetor: {len(embeddings_gemini[0])}\")"]},{"cell_type":"code","execution_count":6,"id":"OHKAXnK1gy6p","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1753475303584,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"OHKAXnK1gy6p"},"outputs":[],"source":["#embeddings_gemini"]},{"cell_type":"markdown","id":"9_hxdslIgTxD","metadata":{"id":"9_hxdslIgTxD"},"source":["[GoogleGenerativeAIEmbeddings](https://python.langchain.com/docs/integrations/text_embedding/google_generative_ai/)"]},{"cell_type":"code","execution_count":7,"id":"aA4JvoP6R-eB","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27700,"status":"ok","timestamp":1753475331286,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"aA4JvoP6R-eB","outputId":"dc82105d-7d82-42e6-8bd2-c2da88695d3d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-7-3595080225.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n","  minilm_embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Tempo de processamento: 0.07621884346008301 segundos\n","  - Dimensões do vetor: 384\n"]}],"source":["## all-MiniLM-L6-v2\n","\n","minilm_embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n","start_time = time.time()\n","embeddings_minilm = minilm_embeddings.embed_documents(textos_teste)\n","end_time = time.time()\n","\n","print(f\"Tempo de processamento: {end_time - start_time} segundos\")\n","print(f\"  - Dimensões do vetor: {len(embeddings_minilm[0])}\")"]},{"cell_type":"code","execution_count":8,"id":"D-Dr5bzbJ8Ga","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1753475331296,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"D-Dr5bzbJ8Ga","outputId":"f426d28a-d5e5-4ae6-8d19-454a96110aef"},"outputs":[{"name":"stdout","output_type":"stream","text":["  - Dimensões do vetor: 384\n"]}],"source":["print(f\"  - Dimensões do vetor: {len(embeddings_minilm[0])}\")"]},{"cell_type":"markdown","id":"uvh0laQHhBH3","metadata":{"id":"uvh0laQHhBH3"},"source":["[HuggingFaceEmbeddings](https://python.langchain.com/api_reference/huggingface/embeddings/langchain_huggingface.embeddings.huggingface.HuggingFaceEmbeddings.html)\n","\n","[all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",")"]},{"cell_type":"code","execution_count":9,"id":"BoYBw-Q_hSbV","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1753475331300,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"BoYBw-Q_hSbV"},"outputs":[],"source":["#embeddings_minilm"]},{"cell_type":"code","execution_count":10,"id":"N4edPr87R_yw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3193,"status":"ok","timestamp":1753475334494,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"N4edPr87R_yw","outputId":"2a01cf25-6f65-4c86-e65f-7627271c5be6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tempo de processamento: 1.6147511005401611 segundos\n","  - Dimensões do vetor: 1024\n"]}],"source":["# BGE-Large\n","\n","bge_embeddings = HuggingFaceEmbeddings(model_name=\"BAAI/bge-large-en-v1.5\")\n","\n","start_time = time.time()\n","embeddings_bge = bge_embeddings.embed_documents(textos_teste)\n","end_time = time.time()\n","\n","print(f\"Tempo de processamento: {end_time - start_time} segundos\")\n","print(f\"  - Dimensões do vetor: {len(embeddings_bge[0])}\")"]},{"cell_type":"markdown","id":"fHX0r2sehcwt","metadata":{"id":"fHX0r2sehcwt"},"source":["[bge-large-en-v1.5](https://huggingface.co/BAAI/bge-large-en-v1.5)"]},{"cell_type":"markdown","id":"56d79d44","metadata":{"id":"56d79d44"},"source":["### Análise de Qualidade Semântica\n","\n","Agora, vamos ver qual modelo entende melhor uma pergunta semanticamente similar, mas com palavras diferentes."]},{"cell_type":"code","execution_count":11,"id":"OBYt8kXCSW_Q","metadata":{"executionInfo":{"elapsed":856,"status":"ok","timestamp":1753475335352,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"OBYt8kXCSW_Q"},"outputs":[],"source":["pergunta = \"Quero tirar uns dias de folga do trabalho.\"\n","\n","emb_pergunta_gemini = gemini_embeddings.embed_query(pergunta)\n","emb_pergunta_minilm = minilm_embeddings.embed_query(pergunta)\n","emb_pergunta_bge = bge_embeddings.embed_query(pergunta)"]},{"cell_type":"code","execution_count":12,"id":"lqUjnYE4SYuE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1753475335360,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"lqUjnYE4SYuE","outputId":"db9662b2-dc17-4971-b76a-fa0347edd66f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Quero tirar uns dias de folga do trabalho.\n"]}],"source":["modelos = {\n","    \"Gemini\": (emb_pergunta_gemini, embeddings_gemini),\n","    \"MiniLM\": (emb_pergunta_minilm, embeddings_minilm),\n","    \"BGE-large\": (emb_pergunta_bge, embeddings_bge)\n","}\n","\n","print(pergunta)"]},{"cell_type":"code","execution_count":13,"id":"deb8c3ef","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1753475335366,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"deb8c3ef","outputId":"3ca38e7b-8ed5-4829-cae6-51c6b1e631cc"},"outputs":[{"name":"stdout","output_type":"stream","text":["--- Ranking para o modelo Gemini ---\n","  1. (Score: 0.824) Quero entender o processo de avaliação de performance.\n","  2. (Score: 0.811) Preciso de um relatório de despesas de viagem.\n","  3. (Score: 0.761) Qual é a política de férias da nossa empresa?\n","\n","--- Ranking para o modelo MiniLM ---\n","  1. (Score: 0.496) Quero entender o processo de avaliação de performance.\n","  2. (Score: 0.469) Onde encontro o código de conduta da organização?\n","  3. (Score: 0.465) Qual é a política de férias da nossa empresa?\n","\n","--- Ranking para o modelo BGE-large ---\n","  1. (Score: 0.646) Qual é a política de férias da nossa empresa?\n","  2. (Score: 0.645) Preciso de um relatório de despesas de viagem.\n","  3. (Score: 0.621) Onde encontro o código de conduta da organização?\n","\n"]}],"source":["for nome, (emb_q, emb_docs) in modelos.items():\n","  similaridades = cosine_similarity([emb_q], emb_docs)[0]\n","  doc_e_similaridade = sorted(\n","      zip(textos_teste, similaridades), key=lambda x: x[1], reverse=True\n","  )\n","  print(f\"--- Ranking para o modelo {nome} ---\")\n","  for i, (doc, sim) in enumerate(doc_e_similaridade[:3], 1):\n","    print(f\"  {i}. (Score: {sim:.3f}) {doc}\")\n","  print()"]},{"cell_type":"markdown","id":"UY1hXDHMif2W","metadata":{"id":"UY1hXDHMif2W"},"source":[" **o BGE-large foi o único modelo que colocou a frase sobre férias (“Qual é a política de férias…”) em 1.º lugar**, exatamente o que esperamos quando a consulta é “Quero tirar uns dias de folga do trabalho.”\n","\n","| Modelo        | Top-1 retornado                                            | Por que não/por que sim?                                                                 |\n","| ------------- | ---------------------------------------------------------- | ---------------------------------------------------------------------------------------- |\n","| **Gemini**    | *“Quero entender o processo de avaliação de performance.”* | O modelo pareceu priorizar a parte “Quero …” e ignorou o tema “folga/férias”.            |\n","| **MiniLM**    | *“Quero entender o processo de avaliação de performance.”* | Patinou de forma parecida com o Gemini; scores baixos (\\~0.49) indicam incerteza.        |\n","| **BGE-large** | *“Qual é a política de férias da nossa empresa?”*          | Captou corretamente o conceito “folga/férias” e trouxe o item mais relevante como Top-1. |\n","\n","### Por que isso acontece?\n","\n","* **Treinamento/Foco linguístico**\n","\n","  * *BGE-large* (BAAI) foi ajustado para “embedding for retrieval” e costuma ser forte em captar semântica, mesmo fora do inglês.\n","  * *Gemini embeddings* ainda estão em pré-lançamento e podem favorecer estruturas de frase (“Quero…”) mais do que o tema.\n","  * *MiniLM* é leve e rápido, mas perde profundidade semântica em queries curtas e fora do domínio do treinamento.\n","\n","* **Tamanho e capacidade**\n","  Modelos maiores (BGE-large ≈ 1 B parâmetros) têm mais “espaço” para nuances semânticas em comparação ao MiniLM-L6-v2 (\\~33 M).\n","\n","* **Idioma misto (PT) e dados de treino**\n","  Nem todos os modelos foram igualmente expostos a português. BGE-large costuma lidar melhor com multilíngue que MiniLM; Gemini ainda pode variar.\n","\n","### Cuidado ao tirar conclusões\n","\n","* **Uma única query não faz estatística** – para bater o martelo, rode um conjunto maior de perguntas e compute métricas como *Top-k accuracy* ou *Mean Reciprocal Rank*.\n","* **Scores não são comparáveis entre modelos** – 0.82 do Gemini ≠ 0.64 do BGE; vale apenas a *ordem* dentro do próprio modelo.\n","* **Combine com filtros/feedback** – se a qualidade for crítica, você pode usar rerankers (e.g. Cohere Rerank, bge-reranker) sobre o Top-k retornado.\n","\n","### O que fazer na prática?\n","\n","1. **Teste com várias consultas reais** do seu domínio.\n","2. **Avalie recall\\@k** (quantas vezes o documento correto aparece no Top-k).\n","3. Se BGE-large mantiver o desempenho, ele é um ótimo candidato como modelo de embeddings – ainda mais rodando localmente, sem custo de API.\n","\n","Assim, para esta consulta específica, o BGE-large realmente se saiu melhor, mas faça um benchmark mais amplo antes de decidir pelo modelo definitivo.\n"]},{"cell_type":"markdown","id":"p-p3kx0DjIid","metadata":{"id":"p-p3kx0DjIid"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","id":"b2ed3680","metadata":{"id":"b2ed3680"},"source":["## 2. Caching de Embeddings: Economia e Velocidade\n","\n","Gerar embeddings, especialmente via API, tem custos de tempo e dinheiro. O cache armazena os embeddings já calculados para evitar retrabalho. Usaremos o `CacheBackedEmbeddings` do LangChain."]},{"cell_type":"code","execution_count":14,"id":"1YKRbQhER5MA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1753475335391,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"1YKRbQhER5MA","outputId":"b02c9056-6c5b-414d-e96a-36c1e4cf5c9b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/langchain/embeddings/cache.py:58: UserWarning: Using default key encoder: SHA‑1 is *not* collision‑resistant. While acceptable for most cache scenarios, a motivated attacker can craft two different payloads that map to the same cache key. If that risk matters in your environment, supply a stronger encoder (e.g. SHA‑256 or BLAKE2) via the `key_encoder` argument. If you change the key encoder, consider also creating a new cache, to avoid (the potential for) collisions with existing keys.\n","  _warn_about_sha1_encoder()\n"]}],"source":["from langchain.storage import LocalFileStore\n","from langchain.embeddings import CacheBackedEmbeddings\n","\n","store = LocalFileStore(\"./cache/\")\n","\n","embedder_principal = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n","\n","cache_embeddings = CacheBackedEmbeddings.from_bytes_store(\n","    embedder_principal,\n","    store,\n","    namespace='gemini_cache'\n",")"]},{"cell_type":"code","execution_count":15,"id":"8-Shlf6RR8dX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1753475335400,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"8-Shlf6RR8dX","outputId":"d37aeeb2-da37-4e3e-a03c-5811fcc4d3db"},"outputs":[{"name":"stdout","output_type":"stream","text":["  - Tempo de execução: 0.0029 segundos.\n"]}],"source":["textos_para_cache = [\"Olá, mundo!\", \"Testando o cache de embeddings.\", \"Olá, mundo!\"]\n","\n","start_time = time.time()\n","embeddings_result_1 = cache_embeddings.embed_documents(textos_para_cache)\n","end_time = time.time()\n","\n","print(f\"  - Tempo de execução: {end_time - start_time:.4f} segundos.\")"]},{"cell_type":"code","execution_count":15,"id":"b82e50b3","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1753475335407,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"b82e50b3"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"e83fef4d","metadata":{"id":"e83fef4d"},"source":["## 3. Batch Processing para Indexação em Larga Escala\n","\n","Ao indexar milhares de documentos, processá-los em lotes (batches) é fundamental. Modelos locais, especialmente, se beneficiam enormemente disso."]},{"cell_type":"code","execution_count":16,"id":"X9wgVb40SA3E","metadata":{"executionInfo":{"elapsed":1666,"status":"ok","timestamp":1753475337083,"user":{"displayName":"Leonardo Pena","userId":"18436870872052683223"},"user_tz":180},"id":"X9wgVb40SA3E"},"outputs":[],"source":["documentos_grandes = [f\"Este é o documento de teste número {i}.\" for i in range(1000)]\n","\n","bge_embedder = HuggingFaceEmbeddings(\n","    model_name=\"BAAI/bge-large-en-v1.5\",\n","    model_kwargs={\"device\": \"cpu\"},\n","    encode_kwargs={\"normalize_embeddings\": True}\n",")\n","\n","batch_sizes = [1, 32, 64, 128]"]},{"cell_type":"code","execution_count":null,"id":"f617d1ea","metadata":{"colab":{"background_save":true},"id":"f617d1ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["  - Batch Size: 1    -\u003e Tempo: 440.51s\n","  - Batch Size: 32   -\u003e Tempo: 172.01s\n","  - Batch Size: 64   -\u003e Tempo: 166.87s\n","  - Batch Size: 128  -\u003e Tempo: 170.64s\n"]}],"source":["for batch_size in batch_sizes:\n","    start_time = time.time()\n","    num_batches = len(documentos_grandes) // batch_size\n","    tempo_estimado = num_batches * (0.1 * batch_size) + (len(documentos_grandes) % batch_size) * 0.1\n","    tempo_real = bge_embedder.client.encode(documentos_grandes, batch_size=batch_size)\n","    end_time = time.time()\n","\n","    print(f\"  - Batch Size: {batch_size:\u003c4} -\u003e Tempo: {end_time - start_time:.2f}s\")"]},{"cell_type":"markdown","id":"ed0a7b36","metadata":{"id":"ed0a7b36"},"source":["## 📚 Resumo Prático da Aula 3\n","\n","- **Qualidade vs. Custo**: Modelos de API como o Gemini oferecem alta qualidade com zero setup, mas a um custo por chamada. Modelos locais como o `BGE-large` oferecem qualidade comparável com custo de infraestrutura, além de privacidade.\n","- **Eficiência é Chave**: `CacheBackedEmbeddings` é uma ferramenta poderosa para economizar dinheiro e tempo, eliminando chamadas redundantes.\n","- **Escalabilidade**: Para indexar grandes volumes, o processamento em lote (batch processing) não é opcional, é uma necessidade.\n"]}],"metadata":{"colab":{"name":"","version":""},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}